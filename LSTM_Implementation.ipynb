{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 568,
      "metadata": {
        "id": "VhNy1N590dZZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Single LSTM Cell (With PyTorch)</b></h1>"
      ],
      "metadata": {
        "id": "hM6uW_boO2pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.LSTMCell(input_size=20,hidden_size=100)"
      ],
      "metadata": {
        "id": "Vc83QaL61bmL"
      },
      "execution_count": 569,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.weight_hh.shape)\n",
        "print(model.weight_ih.shape)\n",
        "print(model.bias_hh.shape)\n",
        "print(model.bias_ih.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SsfLJHyby0l",
        "outputId": "3d6aba73-5378-4519-b255-03e906d170b1"
      },
      "execution_count": 570,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([400, 100])\n",
            "torch.Size([400, 20])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Single LSTM Cell (Without PyTorch)</b></h1>"
      ],
      "metadata": {
        "id": "rhclmPQOIfRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def lstm_cell(x,h,c,W_hh,W_ih,b):\n",
        "  i,f,g,o = np.split(W_hh@h + W_ih@x + b , 4)\n",
        "  i,f,g,o = sigmoid(i),sigmoid(f),np.tanh(g),sigmoid(o)\n",
        "  c_t = f*c + i*g\n",
        "  h_t = o * np.tanh(c_t)\n",
        "  return h_t , c_t"
      ],
      "metadata": {
        "id": "jtPiX6zcH5Wm"
      },
      "execution_count": 571,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>LSTM Cell Validity Check</b></h2>"
      ],
      "metadata": {
        "id": "A0calNfSW5It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = np.random.randn(1,20).astype(np.float32)\n",
        "h0 = np.random.randn(1,100).astype(np.float32)\n",
        "c0 = np.random.randn(1,100).astype(np.float32)\n",
        "\n",
        "h_ , c_ = model(torch.tensor(x0) , (torch.tensor(h0) , torch.tensor(c0)))"
      ],
      "metadata": {
        "id": "MqEmaLdPIaz_"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h , c = lstm_cell(x0[0],h0[0],c0[0],\n",
        "                model.weight_hh.detach().numpy(),\n",
        "                model.weight_ih.detach().numpy(),\n",
        "                (model.bias_hh + model.bias_ih).detach().numpy())"
      ],
      "metadata": {
        "id": "z-MrpKKCQI8q"
      },
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.linalg.norm(c - c_[0].detach().numpy()))\n",
        "print(np.linalg.norm(h - h_[0].detach().numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhJRFCinTIDs",
        "outputId": "740a64c0-73dd-4394-eee2-2279b87ba116"
      },
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.2234015e-07\n",
            "2.483791e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Sequence LSTM (With PyTorch)</b></h1>"
      ],
      "metadata": {
        "id": "yWMFeRYSWx0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.LSTM(input_size=20,hidden_size=100,num_layers=1)"
      ],
      "metadata": {
        "id": "tRH7U2B9TjMR"
      },
      "execution_count": 575,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Sequence LSTM (Without PyTorch)</b></h1>"
      ],
      "metadata": {
        "id": "9HxcgsYYb8yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following the convention of PyTorch we will return the hidden state of\n",
        "# all time steps up until now and the current memory state\n",
        "def lstm(X,h,c,W_hh,W_ih,b):\n",
        "  H = np.zeros((X.shape[0], h.shape[0]))\n",
        "  for t in range(X.shape[0]):\n",
        "    h , c = lstm_cell(X[t],h,c,W_hh,W_ih,b)\n",
        "    H[t] = h\n",
        "  return H , c"
      ],
      "metadata": {
        "id": "CQJCukF8buzc"
      },
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Sequence LSTM validity check</b></h2>"
      ],
      "metadata": {
        "id": "EIUhoyxkEtXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randn(50,20).astype(np.float32)\n",
        "h0 = np.random.randn(1,100).astype(np.float32)\n",
        "c0 = np.random.randn(1,100).astype(np.float32)"
      ],
      "metadata": {
        "id": "sIWPd75gZcUh"
      },
      "execution_count": 577,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H,c = lstm(X,h0[0],c0[0],\n",
        "            model.weight_hh_l0.detach().numpy(),\n",
        "            model.weight_ih_l0.detach().numpy(),\n",
        "           (model.bias_hh_l0 + model.bias_ih_l0).detach().numpy())"
      ],
      "metadata": {
        "id": "JYuVFtf9q59e"
      },
      "execution_count": 578,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_,(h_,c_) = model(torch.tensor(X),(torch.tensor(h0),torch.tensor(c0)))"
      ],
      "metadata": {
        "id": "yd7uOFkLYl48"
      },
      "execution_count": 579,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(H - H_.detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el88WQHTZrhl",
        "outputId": "7d655cf1-2104-4e8a-f4a8-afcfdc66929f"
      },
      "execution_count": 580,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(1.5254268484843015e-06)"
            ]
          },
          "metadata": {},
          "execution_count": 580
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HPCa5W_iYfZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Batching</b></h1>\n",
        "\n",
        "\n",
        "> A true LSTM model, as is the case with PyTorch, takes a batch of sequences as input.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Looking at the definition of the LSTM model in PyTorch documentation we will realize that the input it takes by default is a tensor of shape `(T,B,n)` (unless you set `batch_first = true`) where :<br>\n",
        "<h4><b>first dimension corresponds to the input at time t</b></h4>\n",
        "<h4><b>Second dimension corresponds to the sequence in batch</b></h4>\n",
        "<h4><b>Third dimension corresponds to positions in an input vector</b></h4><br>\n",
        "\n",
        "However from intuition, input representation of shape `(B,T,n)` is more logical and matches the <b>top-down</b> structure of the training dataset that we input to the LSTM.\n",
        "\n",
        "- <h2>Why ?</h2>\n",
        "\n",
        "With the representation in the form `(B,T,n)` the matrix of input vectors at time step `t` accessed through `X[:,t,:]` will not be <u>retrieved contiguously and thus inefficient</u>.However using the `(T,B,n)` representation the matrix of inputs at time t will be accessed through `X[t,:,:]` in a way that all the elements are in a <b>contiguous</b> block of memory. Moreover these matrices themselves are also stored contiguously ` X[0,:,:], X[1,:,:] , X[2,:,:] , ...`."
      ],
      "metadata": {
        "id": "SJ0hqv1UB1vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Full LSTM model (Batch Version)</b></h1>\n",
        "\n",
        "Here the only difference from the sequence LSTM cell is that now we have the `x_t,h_t-1 and c_t-1` not just from **one sequence** but from **a batch of sequences** and thus `x, h, c` would be matrices. So when splitting we have to specify with respect to which axis are we gonna split it.\n",
        "\n",
        "\n",
        "\n",
        "> Only a slight change in sequence LSTM cell and LSTM model is needed.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M04SZR_EZ_YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def lstm_cell(x, h, c, W_hh, W_ih, b):\n",
        "  i,f,g,o = np.split(W_hh@(h.T) + W_ih@(x.T) + b,4, axis = 0)\n",
        "  i,f,g,o = sigmoid(i),sigmoid(f),np.tanh(g),sigmoid(o)\n",
        "  i,f,g,o = i.T,f.T,g.T,o.T\n",
        "  c_t = f*c + i*g\n",
        "  h_t = o*np.tanh(c_t)\n",
        "\n",
        "  return h_t , c_t\n",
        "\n",
        "\n",
        "def lstm(X,h,c,W_hh,W_ih,b):\n",
        "  H = np.zeros((X.shape[0],X.shape[1],h.shape[1]))\n",
        "  for t in range(X.shape[0]):\n",
        "    h , c = lstm_cell(X[t],h,c,W_hh,W_ih,b)\n",
        "    H[t] = h\n",
        "  return H , c"
      ],
      "metadata": {
        "id": "WyyOINO9rkST"
      },
      "execution_count": 581,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Batch LSTM Validity Check</b></h2>"
      ],
      "metadata": {
        "id": "nriEhn3TFIdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randn(50,128,20).astype(np.float32)\n",
        "h0 = np.random.randn(1,128,100).astype(np.float32)\n",
        "c0 = np.random.randn(1,128,100).astype(np.float32)"
      ],
      "metadata": {
        "id": "yLrJOo7uou4n"
      },
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_,(h_,c_) = model(torch.tensor(X),(torch.tensor(h0),torch.tensor(c0)))"
      ],
      "metadata": {
        "id": "4eABmTtVx500"
      },
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H , c = lstm(X,h0[0],c0[0],\n",
        "             model.weight_hh_l0.detach().numpy(),\n",
        "             model.weight_ih_l0.detach().numpy(),\n",
        "             (model.bias_hh_l0 + model.bias_ih_l0)[:,None].detach().numpy())"
      ],
      "metadata": {
        "id": "E8PQOT2_sltX"
      },
      "execution_count": 584,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.linalg.norm(H - H_.detach().numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njlN7Ws-uySr",
        "outputId": "52122928-b815-43c9-a9db-51a53c7866f5"
      },
      "execution_count": 585,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.928616607572253e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCtAHvXC2aGe"
      },
      "execution_count": 585,
      "outputs": []
    }
  ]
}